<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python基础</title>
      <link href="/2019/02/06/python%E5%9F%BA%E7%A1%80/"/>
      <url>/2019/02/06/python%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/assets/blogImg/landscape.jpg" alt="Plandscape"></p><blockquote><p>人生苦短 快用Python</p></blockquote><a id="more"></a><p>#python简介<br>Python是动态类型的高级语言、强类型语言、解释型语言、面向对象语言</p><p>##1.Python相关链接</p><p>###1.1Python官方文档：<br>Python3：<a href="https://docs.python.org/release/3.7.0/" target="_blank" rel="noopener">https://docs.python.org/release/3.7.0/</a><br>Python2：<a href="https://docs.python.org/release/2.7.15/" target="_blank" rel="noopener">https://docs.python.org/release/2.7.15/</a><br>Python文档全部：<a href="https://www.python.org/doc/versions/" target="_blank" rel="noopener">https://www.python.org/doc/versions/</a></p><p>###1.2Python第三方库集合:<br>Python库列表：<a href="https://pypi.org/" target="_blank" rel="noopener">https://pypi.org/</a></p><p>###1.3Python学习网站：<br>廖雪峰的官方网站 菜鸟教程</p><p>###1.4Python开发工具<br>PyCharm、notepad++、sublime text、Xcode</p><p>#安装python环境<br>Mac 自带python2，但是python2终究要被淘汰。<br>Anaconda自带python3环境，推荐安装。由于官网的网速实在太慢，推荐清华大学的镜像下载<br><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a><br>安装完Anaconda之后 可以库管理那里添加两个源<br><a href="https://pypi.python.org/simple" target="_blank" rel="noopener">https://pypi.python.org/simple</a><br><a href="https://pypi.mirrors.ustc.edu.cn/simple" target="_blank" rel="noopener">https://pypi.mirrors.ustc.edu.cn/simple</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫环境准备</title>
      <link href="/2019/02/06/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2/"/>
      <url>/2019/02/06/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/assets/blogImg/python.jpg" alt="Python Logo"></p><blockquote><p>人生苦短 快用Python</p></blockquote><a id="more"></a><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>后续所有操作都是基于Mac 10.14系统环境</p><h2 id="安装python环境"><a href="#安装python环境" class="headerlink" title="安装python环境"></a>安装python环境</h2><p>Mac 自带python2，但是python2终究要被淘汰。<br>Anaconda自带python3环境，推荐安装。由于官网的网速实在太慢，推荐清华大学的镜像下载<br><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a><br>安装完Anaconda之后 可以库管理那里添加两个源<br><a href="https://pypi.python.org/simple" target="_blank" rel="noopener">https://pypi.python.org/simple</a><br><a href="https://pypi.mirrors.ustc.edu.cn/simple" target="_blank" rel="noopener">https://pypi.mirrors.ustc.edu.cn/simple</a></p><h2 id="安装请求库"><a href="#安装请求库" class="headerlink" title="安装请求库"></a>安装请求库</h2><p>爬虫可以简单的分为：抓取页面-分析页面-存储数据<br>在抓取页面的过程中，需要模拟器浏览器向服务器发出请求，借助以下库来实现HTTP请求操作<br>推荐使用pip安装</p><h3 id="request库的安装"><a href="#request库的安装" class="headerlink" title="request库的安装"></a>request库的安装</h3><p>pip install requests</p><h3 id="Selenium的安装"><a href="#Selenium的安装" class="headerlink" title="Selenium的安装"></a>Selenium的安装</h3><p>Selenium可以帮助我们驱动浏览器执行特定的动作<br>pip install selenium</p><h3 id="ChromeDriver的安装"><a href="#ChromeDriver的安装" class="headerlink" title="ChromeDriver的安装"></a>ChromeDriver的安装</h3><p>在使用Selenium驱动浏览器时，需要配置对应的驱动<br>下面是谷歌浏览器与chromedriver的版本对应关系，供参考：<br>ChromeDriver v2.46 (2019-02-01)———-Supports Chrome v71-73<br>ChromeDriver v2.45 (2018-12-10)———-Supports Chrome v70-72<br>ChromeDriver v2.44 (2018-11-19)———-Supports Chrome v69-71<br>ChromeDriver v2.43 (2018-10-16)———-Supports Chrome v69-71<br>ChromeDriver v2.42 (2018-09-13)———-Supports Chrome v68-70<br>ChromeDriver v2.41 (2018-07-27)———-Supports Chrome v67-69<br>ChromeDriver v2.40 (2018-06-07)———-Supports Chrome v66-68<br>ChromeDriver v2.39 (2018-05-30)———-Supports Chrome v66-68<br>ChromeDriver v2.38 (2018-04-17)———-Supports Chrome v65-67<br>ChromeDriver v2.37 (2018-03-16)———-Supports Chrome v64-66<br>ChromeDriver v2.36 (2018-03-02)———-Supports Chrome v63-65<br>ChromeDriver v2.35 (2018-01-10)———-Supports Chrome v62-64<br>所有chromedriver均可在下面链接中下载到：<br><a href="http://npm.taobao.org/mirrors/chromedriver/" target="_blank" rel="noopener">http://npm.taobao.org/mirrors/chromedriver/</a><br>下载完成之后，进入ChromeDriver所在目录，将其移动到/usr/bin目录下<br>sudo mv chromedriver /usr/bin<br>进入该目录检查一下<br>cd /usr/bin<br>chromedriver –version<br>加入环境变量<br>1.cd ~ #进入～目录<br>2.open -e .bash_profile #打开配置文件<br>3.请在结束符前输入 export PATH=$PATH:/usr/local/bin/ChromeDriver #记得保存<br>4.source .bash_profile #使之生效<br><img src="media/15527024253456/15527069052733.jpg" alt="-w640"></p><h3 id="PhantomJS的安装"><a href="#PhantomJS的安装" class="headerlink" title="PhantomJS的安装"></a>PhantomJS的安装</h3><p>PhantomJS是一个无界面，可编程的WebKit浏览器引擎，支持多种Web标准：DOM操作，CSS选择器，JSON,Canvas以及SVG<br>直接去官网下载 <a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">http://phantomjs.org/download.html</a><br>然后将PhantomJS加入环境变量 方法同上<br><img src="media/15527024253456/15527130244640.jpg" alt="-w640"></p><h3 id="aiohttp库的安装"><a href="#aiohttp库的安装" class="headerlink" title="aiohttp库的安装"></a>aiohttp库的安装</h3><p>request库是一个阻塞式HTTP请求库，也就是当我们发出一个请求时，程序会一直等待服务器响应，直到得到响应后，程序才会进入下一步的处理。<br>aiohttp库则可以提供异步Web服务，这样就可以在等待过程中做一些其他的事，提前效率。<br>pip install aiohttp<br>此外，官方还推荐安装如下两个库：一个是字符编码检测库cchardet，另一个是加速DNS解析库aiodns。同样采用pip安装<br>pip install cchardet<br>pip install aiodns</p><h2 id="解析库的安装"><a href="#解析库的安装" class="headerlink" title="解析库的安装"></a>解析库的安装</h2><p>抓取网页代码之后，下一步就是从网页中提取信息，python有很多强大的解析库供我们使用</p><h3 id="lxml库的安装"><a href="#lxml库的安装" class="headerlink" title="lxml库的安装"></a>lxml库的安装</h3><p>lxml支持HTML和XML的解析，支持XPATH解析方式，而且解析效率很高<br>pip install lxml</p><h3 id="Beautiful-Soup库的安装"><a href="#Beautiful-Soup库的安装" class="headerlink" title="Beautiful Soup库的安装"></a>Beautiful Soup库的安装</h3><p>lxml支持HTML和XML的解析，我们可以用它来方便的从网页中提取数据，他拥有强大的API和多样的解析方式。<br>pip install beautifulsoup4</p><h3 id="pyquery库的安装"><a href="#pyquery库的安装" class="headerlink" title="pyquery库的安装"></a>pyquery库的安装</h3><p>pyquery提供了和jQuery类似的语法来解析HTML文档<br>pip install pyquery</p><h3 id="tesserocr库的安装"><a href="#tesserocr库的安装" class="headerlink" title="tesserocr库的安装"></a>tesserocr库的安装</h3><p>遇到验证码时，我们可以通过OCR来识别<br>tesserocr是Python的一个OCR识别库，但其实是对tesseract做的一层Python API封装，所以他的核心是tesseract，因此，必须先要安装tesseract<br>Mac上使用Homebrew安装IamgeMaick和tesseract库<br>brew install imagemagick<br>brew install tesseract<br>pip install tesserocr pillow</p><p>##数据库的安装<br>数据库可以分为关系型数据库和非关系型数据库<br>关系型数据库如MySQL,Oracle，其数据库是以表的形式存储<br>非关系型数据库如Redis，MongoDB，他们的存储形式是键值对，存储形式更加灵活</p><h3 id="MySQL的安装"><a href="#MySQL的安装" class="headerlink" title="MySQL的安装"></a>MySQL的安装</h3><p>MySQL是一个轻量级的关系型数据库<br>brew install mysql<br>启动，停止，重启MySQL的命令如下<br>sudo mysql.server start<br>sudo mysql.server stop<br>sudo mysql.server restart</p><h2 id="存储库的安装"><a href="#存储库的安装" class="headerlink" title="存储库的安装"></a>存储库的安装</h2><h3 id="PyMySQL的安装"><a href="#PyMySQL的安装" class="headerlink" title="PyMySQL的安装"></a>PyMySQL的安装</h3><p>将数据存储到MySQL中，就需要借助PyMySQL来操作<br>pip install pymysql</p><h2 id="Web库的安装"><a href="#Web库的安装" class="headerlink" title="Web库的安装"></a>Web库的安装</h2><p>使用这些Web服务器程序来搭建一些API接口，供我们爬虫使用。<br>Web服务程序主要介绍Flask和Tornado。</p><h3 id="Flask的安装"><a href="#Flask的安装" class="headerlink" title="Flask的安装"></a>Flask的安装</h3><p>Flask是一个轻量级的Web服务程序，主要用来提供一些API服务。<br>pip install flask</p><h3 id="Tornado的安装"><a href="#Tornado的安装" class="headerlink" title="Tornado的安装"></a>Tornado的安装</h3><p>Tornado是一个支持异步的Web框架，通过使用非阻塞I/O流。他可以支撑成千上万的开放链接，效率非常高。<br>pip install tornado</p><h2 id="App爬取相关库的安装"><a href="#App爬取相关库的安装" class="headerlink" title="App爬取相关库的安装"></a>App爬取相关库的安装</h2><p>暂时忽略</p><h2 id="爬虫框架的安装"><a href="#爬虫框架的安装" class="headerlink" title="爬虫框架的安装"></a>爬虫框架的安装</h2><p>主要介绍pyspider和Scrapy</p><h3 id="pyspider的安装"><a href="#pyspider的安装" class="headerlink" title="pyspider的安装"></a>pyspider的安装</h3><p>pip install pyspider</p><h3 id="Scrapy的安装"><a href="#Scrapy的安装" class="headerlink" title="Scrapy的安装"></a>Scrapy的安装</h3><p>pip install Scrapy</p><h3 id="Scrapy-Splash的安装"><a href="#Scrapy-Splash的安装" class="headerlink" title="Scrapy-Splash的安装"></a>Scrapy-Splash的安装</h3><p>Scrapy-Splash是一个Scrapy中支持JavaScript渲染的工具<br>Scrapy-Splash的安装分为两部分，一个是Splash服务的安装，具体是通过Docker，安装之后，会启动一个Splash服务，我们可以通过他的接口实现JavaScript页面的加载，另外一个Scrapy-Splash的Python库的安装，完成之后即可在Scrapy中使用Splash服务<br>1.安装Splash<br>推荐采用docker安装，所以先安装Docker<br>brew cask install docker<br>docker run -p 8050:8050 scrapinghub/splash<br>2.安装Scrapy-Splash<br>pip install scrapy-splash</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
